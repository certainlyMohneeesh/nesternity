import fetch from 'node-fetch';
import { IProvider } from '../provider';
import { ChatMessage, CompletionOptions } from '../gemini';

export class LocalProvider implements IProvider {
  private endpoint = process.env.AI_MODEL_ENDPOINT || 'http://localhost:8080';

  async generateCompletion(messages: ChatMessage[], options?: CompletionOptions) {
    const payload = { prompt: messages.map(m => `${m.role.toUpperCase()}: ${m.content}`).join('\n\n'), max_new_tokens: options?.maxTokens || 512 };
    const res = await fetch(`${this.endpoint}/generate`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
    if (!res.ok) throw new Error(`Local generate failed: ${res.status}`);
    const json: any = await res.json();
    const text = (json?.text || json?.generated_text || json?.result || '').toString();
    return { content: text, usage: undefined, model: process.env.AI_LOCAL_MODEL || 'local-model' };
  }

  async generateStructuredCompletion<T = unknown>(messages: ChatMessage[], options?: CompletionOptions) {
    const result = await this.generateCompletion(messages, options);
    try {
      const data = JSON.parse(result.content) as T;
      return { data, usage: result.usage, model: result.model };
    } catch (e) {
      throw new Error('Local provider returned invalid JSON');
    }
  }

  async embedText(texts: string[]): Promise<number[][]> {
    const res = await fetch(`${this.endpoint}/embed`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ texts }) });
    if (!res.ok) throw new Error(`Local embed failed: ${res.status}`);
    const json: any = await res.json();
    return json?.embeddings ?? [];
  }

  async searchEmbeddings(query: string, topK: number = 5) { return []; }
  async healthCheck(): Promise<boolean> { try { const r = await fetch(`${this.endpoint}/health`); return r.ok; } catch { return false; } }
}

export default LocalProvider;
